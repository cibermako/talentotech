{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAREA 1: Métodos de aprendizaje conjunto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preguntas conceptuales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. ¿Si un algoritmo `gradient boosting ensemble` muestra `sobreajuste`, ¿debería aumentar o disminuir la tasa de aprendizaje? Argumente su respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**\n",
    "\n",
    "Se debería disminuir la tasa de aprendizaje.  El Gradient Boosting,  construye modelos secuenciales donde cada nuevo modelo corrige los errores del modelo anterior.  La tasa de aprendizaje afecta la velocidad con la que el modelo se ajusta a los datos. Si se disminuye la tasa de aprendizaje, cada nuevo  modelo efecta menos sobre la predicción final. por tanto el algoritmo hace correcciones más pequeñas en cada iteración es decir es mas gradual y controlado y disminuyendo el riesgo de sobreajuse.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Si ha entrenado 5 `modelos diferentes` de clasificación con exactamente los mismos datos de entrenamiento y todos ellos alcanzan una exactitud (`accuracy`) del $95\\%$, ¿existe alguna posibilidad de que pueda combinar estos modelos para obtener mejores resultados? Si es así, ¿cómo? Si no, ¿por qué?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**\n",
    "Sí es posible mejorar los resultados combinando los modelos, al ser metodos diferentes, los errores pueden ser diferentes y por tanto al combinarlos se complementan y se puede reducir el error total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Suponga que en el escenario de la pregunta `1.2` se combinan los `5` clasificadores base medianyte el método de `voto mayoriatario duro`. Calcule el error del clasificador conjunto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del Voting Classifier: 1.00\n",
      "Error del clasificador conjunto: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías necesarias\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar un conjunto de datos (por ejemplo, el conjunto de datos Iris)\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X\n",
    "y\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Definir los cinco modelos base\n",
    "modelo1 = DecisionTreeClassifier(max_depth=3, random_state=42)  # Árbol de decisión\n",
    "modelo2 = SVC(probability=True, kernel='linear', random_state=42)  # Support Vector Classifier con kernel lineal\n",
    "modelo3 = KNeighborsClassifier(n_neighbors=5)  # K-Nearest Neighbors\n",
    "modelo4 = GaussianNB()  # Naive Bayes Gaussiano\n",
    "modelo5 = LogisticRegression(max_iter=1000, random_state=42)  # Regresión logística\n",
    "\n",
    "# Crear el Voting Classifier con voting='hard' (voto mayoritario duro)\n",
    "votador = VotingClassifier(estimators=[\n",
    "    ('decision_tree', modelo1),\n",
    "    ('svc', modelo2),\n",
    "    ('knn', modelo3),\n",
    "    ('naive_bayes', modelo4),\n",
    "    ('logistic_regression', modelo5)\n",
    "], voting='hard')\n",
    "\n",
    "# Ajustar el Voting Classifier a los datos de entrenamiento\n",
    "votador.fit(X_train, y_train)\n",
    "\n",
    "# Predecir las etiquetas para el conjunto de prueba\n",
    "predicciones_conjunto = votador.predict(X_test)\n",
    "\n",
    "# Calcular la exactitud del clasificador conjunto\n",
    "exactitud = accuracy_score(y_test, predicciones_conjunto)\n",
    "print(f'Exactitud del Voting Classifier: {exactitud:.2f}')\n",
    "\n",
    "# Calcular el error del clasificador conjunto\n",
    "error = 1 - exactitud\n",
    "print(f'Error del clasificador conjunto: {error:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Exactitud: 1.00, Error: 0.00\n",
      "SVM - Exactitud: 1.00, Error: 0.00\n",
      "KNN - Exactitud: 1.00, Error: 0.00\n",
      "Naive Bayes - Exactitud: 0.98, Error: 0.02\n",
      "Logistic Regression - Exactitud: 1.00, Error: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Evalua de forma individual \n",
    "modelos_base = {\n",
    "    'Decision Tree': modelo1,\n",
    "    'SVM': modelo2,\n",
    "    'KNN': modelo3,\n",
    "    'Naive Bayes': modelo4,\n",
    "    'Logistic Regression': modelo5\n",
    "}\n",
    "\n",
    "\n",
    "for nombre, modelo in modelos_base.items():\n",
    "    modelo.fit(X_train, y_train)\n",
    "    predicciones = modelo.predict(X_test)\n",
    "    exactitud = accuracy_score(y_test, predicciones)\n",
    "    error = 1 - exactitud\n",
    "    print(f'{nombre} - Exactitud: {exactitud:.2f}, Error: {error:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. ¿Si un algoritmo `Adaboost` muestra `subajuste`, ¿qué hiperparámetros debería ajustar y cómo? Argumente su respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respuesta\n",
    "Significa que el modelo es demasiado simple para capturar la complejidad de los datos y, por lo tanto, no está obteniendo un rendimiento adecuado tanto en el conjunto de entrenamiento como en el de prueba. \n",
    "Para mejorar el rendimiento y reducir el subajuste, se pueden ajustar varios Hiperparametros:\n",
    "\n",
    "1. Aumentar el número de estimadores. puede ayudar a reducir el subajuste, ya que permite que el modelo aprenda más características de los datos. \n",
    "2. Reducir la tasa de aprendizaje.  puede ayudar a mejorar el rendimiento al hacer que el modelo se ajuste más lentamente y de manera más precisa a los datos. \n",
    "3. Incrementar la profundidad de los árboles, permite que cada clasificador débil sea más complejo, lo cual puede ayudar a reducir el subajuste. \n",
    "4. Cambiar el clasificador débil a uno más complejo, como un árbol de decisión de mayor profundidad o incluso otros modelos más sofisticados, puede ayudar a capturar mejor las características de los datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ejercicio(s) práctico(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos `mnist_784`, contiene 70.000 pequeñas imágenes de dígitos escritos a mano por estudiantes de secundaria y empleados de la Oficina del Censo de EE.UU. Es posible acceder a este dataset medinte las siguientes instrucciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.27 s\n",
      "Wall time: 26.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9    ...  774  775  776  \\\n",
       "0        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "1        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "4        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "69995    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "69996    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "69997    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "69998    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "69999    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "       777  778  779  780  781  782  783  \n",
       "0        0    0    0    0    0    0    0  \n",
       "1        0    0    0    0    0    0    0  \n",
       "2        0    0    0    0    0    0    0  \n",
       "3        0    0    0    0    0    0    0  \n",
       "4        0    0    0    0    0    0    0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "69995    0    0    0    0    0    0    0  \n",
       "69996    0    0    0    0    0    0    0  \n",
       "69997    0    0    0    0    0    0    0  \n",
       "69998    0    0    0    0    0    0    0  \n",
       "69999    0    0    0    0    0    0    0  \n",
       "\n",
       "[70000 rows x 784 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', as_frame=False)\n",
    "X, y = mnist.data, mnist.target\n",
    "\n",
    "pd.DataFrame(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La etiqueta de esta imagen es:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_digit(image_data):\n",
    "    image = image_data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "print(\"La etiqueta de esta imagen es: \", y[12])\n",
    "plot_digit(X[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.1 Escale todas las `784` variables con el método `min-max`; pero usando en máximo y el mínimo globales, en lugar de los de cada columna. Vrase el `ejercicio 0312` del capítulo 5, unidad 8 (`ensemble algorithms`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.2 Divida los datos en un conjunto de entrenamiento y un conjunto de prueba (utilizar $60.000$ registros para el entrenamiento y $10.000$ para prueba). Luego, entrene los siguientes clasificadores optimizando los `hiperparámetros` más representativos (excepto los de regularización) mediante la `validación cruzada `:\n",
    "\n",
    "  - clasificador SVM.\n",
    "  - Regresión logística\n",
    "  - Naive Bayes\n",
    "  - K-vecinos\n",
    "  - Árbol de decisión\n",
    "\n",
    "  Compare los rendimientos de cada uno de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.3 Utilizando la combinación de hiperparámetroas más óptima para cada uno de los modelos anteriores, construya un clasificador por `voto mayoritario` tanto tipo `hard` como tipo `soft`. Elejia el más `eficiente` de los dos métodos y compare su rendimientro contra el mejor clasificador undividual del numeral anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.4 Utilice el `mejor modelo individual` hallado en el numeral `2.2` y contruya un clasificador con el método `Bagging`. Compare su rendimiento con los modelos anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.5 Utilizando los hiperparámetros del mejor `árbol de decisión` construido en el numeral `2.2`, entrene un `bosque alretorio` y utilice la validación cruzada afinar solamente un hiperparámetro: `n_estimators`. Compare su rendimiento con los modelos anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.6 Utilice el `mejor modelo individual` hallado en el numeral `2.2` y contruya un clasificador con el método `AdaBoost`y utilice la validación cruzada afinar solamente dos hiperparámetros: `n_estimators` y `learning_rate`. Compare su rendimiento con los modelos anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.7 Utilizando los hiperparámetros del mejor `árbol de decisión` construido en el numeral `2.2`, entrene un `GradientBoostingClassifier` y utilice la validación cruzada afinar solamente dos hiperparámetros: `n_estimators` y `learning_rate`. Compare su rendimiento con los modelos anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.8 Utilizando los hiperparámetros del mejor `árbol de decisión` construido en el numeral `2.2`, entrene un `XGBClassifier` y utilice la validación cruzada afinar solamente dos hiperparámetros: `n_estimators` y `learning_rate`. Compare su rendimiento con los modelos anteriores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.9 Elija `el mejor clasificador` de entre todos los entrenados previamente y argumente su respuesta."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SFC_V2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
